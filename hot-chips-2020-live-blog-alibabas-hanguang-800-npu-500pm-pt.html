<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta name=description content="07:58PM EDT - Former Huawei GPU architect 07:59PM EDT - Development in early 2018 08:00PM EDT - Lots of business on inferencing 08:00PM EDT - achieve high-throughput, low latency, high power efficiency design"><meta name=generator content="Hugo 0.98.0"><meta name=robots content="index,follow,noarchive"><title>Alibaba's Hanguang 800 NPU (5:00pm PT) &#183;</title><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css><!--[if lte IE 8]><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css><![endif]--><!--[if gt IE 8]><!--><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css><!--<![endif]--><!--[if lte IE 8]><link rel=stylesheet href=https://assets.cdnweb.info/hugo/blackburn/css/side-menu-old-ie.css><![endif]--><!--[if gt IE 8]><!--><link rel=stylesheet href=https://assets.cdnweb.info/hugo/blackburn/css/side-menu.css><!--<![endif]--><link rel=stylesheet href=https://assets.cdnweb.info/hugo/blackburn/css/blackburn.css><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.2/css/all.min.css><link rel=preconnect href=https://fonts.gstatic.com><link href="https://fonts.googleapis.com/css2?family=Raleway&display=swap" rel=stylesheet type=text/css><script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/styles/androidstudio.min.css><script async src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/10.6.0/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><link rel="shortcut icon" href=./img/favicon.ico type=image/x-icon></head><body><div id=layout><a href=#menu id=menuLink class=menu-link><span></span></a><div id=menu><a class="pure-menu-heading brand" href=./index.html>RiffVib</a><div class=pure-menu><ul class=pure-menu-list><li class=pure-menu-item><a class=pure-menu-link href=./index.html><i class="fa fa-home fa-fw"></i>Home</a></li><li class=pure-menu-item><a class=pure-menu-link href=./post/index.html><i class="fa fa-list fa-fw"></i>Posts</a></li><li class=pure-menu-item><a class=pure-menu-link href=./sitemap.xml><i class="fa fa-user fa-fw"></i>Sitemap</a></li><li class=pure-menu-item><a class=pure-menu-link href=./index.xml><i class="fa fa-phone fa-fw"></i>RSS</a></li></ul></div><div class="pure-menu social"><ul class=pure-menu-list></ul></div><div><div class=small-print><small>&copy; 2022. All rights reserved.</small></div><div class=small-print><small>Built with&nbsp;<a href=https://gohugo.io/ target=_blank>Hugo</a></small>
<small>Theme&nbsp;<a href=https://github.com/yoshiharuyamashita/blackburn target=_blank>Blackburn</a></small></div></div></div><div id=main><div class=header><h1>Alibaba's Hanguang 800 NPU (5:00pm PT)</h1><h2>07:58PM EDT - Former Huawei GPU architect 07:59PM EDT - Development in early 2018 08:00PM EDT - Lots of business on inferencing 08:00PM EDT - achieve high-throughput, low latency, high power efficiency design</h2></div><div class=content><div class=post-meta><div><i class="fa fa-calendar fa-fw"></i>
<time>03 Feb 2024, 00:00</time></div></div><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190059261_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818195855 href=#><span class=lb_time>07:58PM EDT</span></a> - Former Huawei GPU architect</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190059571_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818195923 href=#><span class=lb_time>07:59PM EDT</span></a> - Development in early 2018</p><p><a id=post0818200002 href=#><span class=lb_time>08:00PM EDT</span></a> - Lots of business on inferencing</p><p><a id=post0818200017 href=#><span class=lb_time>08:00PM EDT</span></a> - achieve high-throughput, low latency, high power efficiency design</p><p><a id=post0818200029 href=#><span class=lb_time>08:00PM EDT</span></a> - Lots of Alibaba workloads are convolution-related</p><p><a id=post0818200034 href=#><span class=lb_time>08:00PM EDT</span></a> - Optimization for GEMM as well</p><p><a id=post0818200050 href=#><span class=lb_time>08:00PM EDT</span></a> - Flexible to support future activation functions</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190101361_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190101451_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818200110 href=#><span class=lb_time>08:01PM EDT</span></a> - 4 cores with ring bus</p><p><a id=post0818200125 href=#><span class=lb_time>08:01PM EDT</span></a> - 192 MB local memory, distributed shared, no DDR</p><p><a id=post0818200136 href=#><span class=lb_time>08:01PM EDT</span></a> - Command processor above all four cores</p><p><a id=post0818200144 href=#><span class=lb_time>08:01PM EDT</span></a> - PCIe 4.0 x16</p><p><a id=post0818200203 href=#><span class=lb_time>08:02PM EDT</span></a> - Each core has three engines: Tensor, Pooling, Memory</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190102551_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818200221 href=#><span class=lb_time>08:02PM EDT</span></a> - This is the tensor engine throughput</p><p><a id=post0818200228 href=#><span class=lb_time>08:02PM EDT</span></a> - data reuse and fused ops</p><p><a id=post0818200233 href=#><span class=lb_time>08:02PM EDT</span></a> - minimize data movement</p><p><a id=post0818200322 href=#><span class=lb_time>08:03PM EDT</span></a> - Use sliding window to minimize access</p><p><a id=post0818200403 href=#><span class=lb_time>08:04PM EDT</span></a> - Convert data to FP and push down the pipe</p><p><a id=post0818200430 href=#><span class=lb_time>08:04PM EDT</span></a> - on EW2 stage</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190105421_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818200511 href=#><span class=lb_time>08:05PM EDT</span></a> - fp19 support</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190105571_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818200547 href=#><span class=lb_time>08:05PM EDT</span></a> - memory engine can adjust arrangement of data</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190106421_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190106511_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818200618 href=#><span class=lb_time>08:06PM EDT</span></a> - Support for compressed models for sparse data</p><p><a id=post0818200631 href=#><span class=lb_time>08:06PM EDT</span></a> - Pruning is optional</p><p><a id=post0818200639 href=#><span class=lb_time>08:06PM EDT</span></a> - Quantized to INT16/INT8</p><p><a id=post0818200659 href=#><span class=lb_time>08:06PM EDT</span></a> - FP24 vector unit</p><p><a id=post0818200707 href=#><span class=lb_time>08:07PM EDT</span></a> - Way buffer</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190108441_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818200818 href=#><span class=lb_time>08:08PM EDT</span></a> - This is a typical workflow</p><p><a id=post0818200925 href=#><span class=lb_time>08:09PM EDT</span></a> - Host CPU communicates to CP</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190110231_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818200949 href=#><span class=lb_time>08:09PM EDT</span></a> - Domain specific instruction set</p><p><a id=post0818200954 href=#><span class=lb_time>08:09PM EDT</span></a> - operation fusion</p><p><a id=post0818200958 href=#><span class=lb_time>08:09PM EDT</span></a> - CISC-like</p><p><a id=post0818201004 href=#><span class=lb_time>08:10PM EDT</span></a> - 3-engine sync</p><p><a id=post0818201024 href=#><span class=lb_time>08:10PM EDT</span></a> - two syncs - at compiler or at hardware</p><p><a id=post0818201144 href=#><span class=lb_time>08:11PM EDT</span></a> - Scalable task mapping</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190112241_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818201211 href=#><span class=lb_time>08:12PM EDT</span></a> - Use PCIe switch for multi-chip pipelining</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190112581_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818201226 href=#><span class=lb_time>08:12PM EDT</span></a> - 825 TOPs INT8 at 280W</p><p><a id=post0818201230 href=#><span class=lb_time>08:12PM EDT</span></a> - 700 MHz</p><p><a id=post0818201233 href=#><span class=lb_time>08:12PM EDT</span></a> - 709 mm2</p><p><a id=post0818201236 href=#><span class=lb_time>08:12PM EDT</span></a> - TSMC 12nm</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190113251_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818201252 href=#><span class=lb_time>08:12PM EDT</span></a> - Support most major frameworks</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190114271_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818201356 href=#><span class=lb_time>08:13PM EDT</span></a> - Support for post-training quantization</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190115231_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190115421_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818201550 href=#><span class=lb_time>08:15PM EDT</span></a> - At batch 1, NPU throughput outperfoms V100 at batch 128</p><p><a id=post0818201558 href=#><span class=lb_time>08:15PM EDT</span></a> - using Resnet50 v1</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190117071_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818201635 href=#><span class=lb_time>08:16PM EDT</span></a> - Scalable perf and power</p><p><a id=post0818201658 href=#><span class=lb_time>08:16PM EDT</span></a> - 25W to 280W</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190117461_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190118251_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190118421_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190120161_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190120311_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818201957 href=#><span class=lb_time>08:19PM EDT</span></a> - Targeting lots of applications</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190121471_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818202132 href=#><span class=lb_time>08:21PM EDT</span></a> - ecs.ebman1.24xlarge us Cascade 104 cores with 4x2-core Hanguang 800</p><p><a id=post0818202146 href=#><span class=lb_time>08:21PM EDT</span></a> - public cloud</p><p><a href=#><img src=https://cdn.statically.io/img/images.anandtech.com/doci/16009/202008190122441_575px.jpg alt style=margin:auto;display:block;text-align:center;max-width:100%;height:auto></a></p><p><a id=post0818202312 href=#><span class=lb_time>08:23PM EDT</span></a> - Q&A Time</p><p><a id=post0818202352 href=#><span class=lb_time>08:23PM EDT</span></a> - Q: Recommendation engines - what other targets? A: Primarily Computer vision, after the optimizations, it's well suited for recommendation and search as well.</p><p><a id=post0818202406 href=#><span class=lb_time>08:24PM EDT</span></a> - Q: Replacing the T4? A: Yes</p><p><a id=post0818202426 href=#><span class=lb_time>08:24PM EDT</span></a> - Q: Embedding tables in host memory? A: correct</p><p><a id=post0818202517 href=#><span class=lb_time>08:25PM EDT</span></a> - Q: Support workloads > 192 MB? A: Can enable multiple chips and chip-to-chip through PCIe</p><p><a id=post0818202530 href=#><span class=lb_time>08:25PM EDT</span></a> - Q: Sparsity engine for weights and activations? A: Just weights</p><p><a id=post0818202624 href=#><span class=lb_time>08:26PM EDT</span></a> - Q: Non-2D convolution like Bert? A: We can map onto our chip and run it with precision to meet requirements, but performance is not satisfied. Size is a problem, so we need multiple chips which has a perf penalty</p><p><a id=post0818202747 href=#><span class=lb_time>08:27PM EDT</span></a> - Q: Why compare A100 and Goya at different batches to NPU? A: We can do single batch throughput better while keeping latency super low</p><p><a id=post0818202749 href=#><span class=lb_time>08:27PM EDT</span></a> - Tjat</p><p><a id=post0818202800 href=#><span class=lb_time>08:28PM EDT</span></a> - That's a wrap. Now for the final talk - silicon photonics!</p><p><a id=post0818202805 href=#><span class=lb_time>08:28PM EDT</span></a> - .</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH53fI9yZqGnpGKwqbXPrGRraGJleq211Z5km6SfnHqiuMibmJuZo2K1orrGrpinn11tfXF5zamsZm1gZb2uec%2Bt</p><h4><i class="fas fa-share-alt" aria-hidden=true></i>&nbsp;Share!</h4><ul class=share-buttons><li><a href="https://www.facebook.com/sharer/sharer.php?u=%2fhot-chips-2020-live-blog-alibabas-hanguang-800-npu-500pm-pt.html" target=_blank title="Share on Facebook"><i class="fab fa-facebook" aria-hidden=true></i><span class=sr-only>Share on Facebook</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="https://twitter.com/intent/tweet?source=%2fhot-chips-2020-live-blog-alibabas-hanguang-800-npu-500pm-pt.html" target=_blank title=Tweet><i class="fab fa-twitter" aria-hidden=true></i><span class=sr-only>Tweet</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="https://plus.google.com/share?url=%2fhot-chips-2020-live-blog-alibabas-hanguang-800-npu-500pm-pt.html" target=_blank title="Share on Google+"><i class="fab fa-google-plus" aria-hidden=true></i><span class=sr-only>Share on Google+</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="http://www.tumblr.com/share?v=3&u=%2fhot-chips-2020-live-blog-alibabas-hanguang-800-npu-500pm-pt.html" target=_blank title="Post to Tumblr"><i class="fab fa-tumblr" aria-hidden=true></i><span class=sr-only>Post to Tumblr</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="http://pinterest.com/pin/create/button/?url=%2fhot-chips-2020-live-blog-alibabas-hanguang-800-npu-500pm-pt.html" target=_blank title="Pin it"><i class="fab fa-pinterest-p" aria-hidden=true></i><span class=sr-only>Pin it</span></a></li>&nbsp;&nbsp;&nbsp;<li><a href="http://www.reddit.com/submit?url=%2fhot-chips-2020-live-blog-alibabas-hanguang-800-npu-500pm-pt.html" target=_blank title="Submit to Reddit"><i class="fab fa-reddit-alien" aria-hidden=true></i><span class=sr-only>Submit to Reddit</span></a></li></ul><style>ul.share-buttons{list-style:none;padding:0}ul.share-buttons li{display:inline}ul.share-buttons .sr-only{position:absolute;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);padding:0;border:0;height:1px;width:1px;overflow:hidden}</style><div class="prev-next-post pure-g"><div class=pure-u-1-24 style=text-align:left><a href=./blog.html><i class="fa fa-chevron-left"></i></a></div><div class=pure-u-10-24><nav class=prev><a href=./blog.html>Blog</a></nav></div><div class=pure-u-2-24>&nbsp;</div><div class=pure-u-10-24><nav class=next><a href=./911-oliver-stark-responds-negative-backlash-character-sexuality.html>9-1-1 star Oliver Stark shares blunt response to negative backlash over characters sexuality reve</a></nav></div><div class=pure-u-1-24 style=text-align:right><a href=./911-oliver-stark-responds-negative-backlash-character-sexuality.html><i class="fa fa-chevron-right"></i></a></div></div></div></div></div><script src=https://assets.cdnweb.info/hugo/blackburn/js/ui.js></script>
<script src=https://assets.cdnweb.info/hugo/blackburn/js/menus.js></script>
<script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/banner.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://js.zainuddin.my.id/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>